{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import load_geolife\n",
    "import add_geohash\n",
    "import create_nodes\n",
    "import geohash_location_count\n",
    "import geohash_user_count\n",
    "import create_geohash_meet\n",
    "import create_geohash_meet_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs():\n",
    "    if not os.path.isdir('images/'):\n",
    "        os.makedirs('images/')\n",
    "    if not os.path.isdir('htmls/'):\n",
    "        os.makedirs('htmls/')\n",
    "    if not os.path.isdir('data/'):\n",
    "        os.makedirs('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDuplicates():\n",
    "    duplicates = pd.read_csv('data/geolife_duplicates_content.csv')\n",
    "    df = pd.read_csv('data/geolife_geohash_size_8.csv')\n",
    "    df['px'] = df['Person ID'].astype('string') + \"_\" + df['Trajectory'].astype('string') + \".plt\"\n",
    "    duplicates['px'] = duplicates['user'].astype('string')+\"_\"+duplicates['file_name'].astype('string')\n",
    "    noduplicates = df[~df['px'].isin(duplicates['px'])].copy(deep=True)\n",
    "    noduplicates.to_csv('data/geolife_geohash_size_8_no_duplicates.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/182 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182/182 [02:55<00:00,  1.04it/s]\n",
      "100%|██████████| 18165801/18165801 [08:47<00:00, 34445.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "415946\n",
      "grouping...\n",
      "grouped\n",
      "1.0 415946 / 415946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414417/414417 [55:03<00:00, 125.46it/s] \n"
     ]
    }
   ],
   "source": [
    "create_dirs()\n",
    "load_geolife.load_geolife('./geolife/Data/')\n",
    "add_geohash.add_geohash()\n",
    "\n",
    "removeDuplicates()\n",
    "create_nodes.create_nodes()\n",
    "geohash_location_count.geohash_location_count()\n",
    "geohash_user_count.geohash_user_count()\n",
    "count_files = create_geohash_meet.createGeohashMeetJsons()\n",
    "create_geohash_meet.createGeohashMeetCSV(count_files)\n",
    "\n",
    "# create_geohash_meet_time.create_geohash_time_meets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def create_geohash_time_meets():\n",
    "    df = pd.read_csv('data/geolife_geohash_meet_intervals_size_8.csv')\n",
    "    df['meets_intervals'] = \"\"\n",
    "\n",
    "    for index in tqdm(df.index):\n",
    "        meets = json.loads(df.loc[index, 'meets_intervals'])\n",
    "        cols = json.loads(df.loc[index, 'meets_intervals_keys'])\n",
    "        all_intervals = {}\n",
    "        for i in meets.keys():\n",
    "            times = meets[i]\n",
    "            interval = []\n",
    "            first_time = [vi for vi in times[0]]\n",
    "            prev_time = [vi for vi in times[0]]\n",
    "            for time in times:\n",
    "                if time[cols.index('Index')] - prev_time[cols.index('Index')] > 1:\n",
    "                    interval.append([\n",
    "                        prev_time[cols.index('Person ID')],\n",
    "                        first_time[cols.index('Timestamp')],\n",
    "                        prev_time[cols.index('Timestamp')],\n",
    "                        prev_time[cols.index('Geohash')],\n",
    "                        first_time[cols.index('Index')],\n",
    "                        prev_time[cols.index('Index')],\n",
    "                        ])\n",
    "                    first_time = [vi for vi in time]\n",
    "                prev_time = [vi for vi in time]\n",
    "\n",
    "            interval.append([\n",
    "                prev_time[cols.index('Person ID')],\n",
    "                first_time[cols.index('Timestamp')],\n",
    "                prev_time[cols.index('Timestamp')],\n",
    "                prev_time[cols.index('Geohash')],\n",
    "                first_time[cols.index('Index')],\n",
    "                prev_time[cols.index('Index')],\n",
    "            ])\n",
    "            all_intervals[i]=interval\n",
    "        df.loc[index, 'meets_intervals'] = json.dumps(all_intervals)\n",
    "        df.loc[index, 'meets_intervals_keys'] = json.dumps([\"Person ID\", \"Start Time\", \"End Time\", \"Geohash\", \"Start Index\", \"End Index\"])\n",
    "    df.to_csv('data/geolife_geohash_meet_intervals_size_8.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
