{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4b8a73-cb0a-4408-9ad5-6f1306c1eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geohash2 as gh\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88536b06-6ec6-42c3-9ca0-f19096af7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('images/'):\n",
    "\tos.makedirs('images/')\n",
    "if not os.path.isdir('htmls/'):\n",
    "\tos.makedirs('htmls/')\n",
    "if not os.path.isdir('data/'):\n",
    "\tos.makedirs('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66131ff1-b1e5-4a90-927f-4f2ab26a8ad5",
   "metadata": {},
   "source": [
    "# 2. Load tdrive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2906c950-0c99-4b6a-8c23-1947dcc5517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10357/10357 [01:36<00:00, 106.96it/s]\n",
      "C:\\Users\\danstorm\\AppData\\Local\\Temp\\ipykernel_13016\\4116393552.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  gps_data = pd.concat(dataframes, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "data_path = './tdrive/taxi_log_2008_by_id/'\n",
    "\n",
    "dataframes = []\n",
    "index = 0\n",
    "dataframes = []\n",
    "\n",
    "for file in tqdm(os.listdir(data_path)):\n",
    "\tfile_path = os.path.join(data_path, file)\n",
    "\n",
    "\ttry:\n",
    "\t\tcolumn_names = ['Person ID', 'Timestamp', 'Longitude', 'Latitude']\n",
    "\t\tlabels_df = pd.read_csv(file_path, sep=',', names=column_names)\n",
    "\n",
    "\t\tdataframes.append(labels_df)\n",
    "\texcept pd.errors.EmptyDataError:\n",
    "\t\tcontinue\n",
    "\n",
    "gps_data = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aee5207",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Person ID', 'Timestamp', 'Longitude', 'Latitude']\n",
    "gps_data.columns = column_names\n",
    "gps_data['Timestamp'] = pd.to_datetime(gps_data['Timestamp'])\n",
    "gps_data = gps_data[gps_data['Latitude'] >= 39.75]\n",
    "gps_data = gps_data[gps_data['Latitude'] <= 40.1]\n",
    "gps_data = gps_data[gps_data['Longitude'] >= 116.18]\n",
    "gps_data = gps_data[gps_data['Longitude'] <= 116.6]\n",
    "gps_data.to_csv(\"data/tdrive_gps_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44735fef-76eb-4df4-aa80-e9310f165df0",
   "metadata": {},
   "source": [
    "# 4. Create Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97f87b7a-18fd-44b4-8cdf-a6a355c0fe1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_taxi_ids = gps_data['Person ID'].unique()\n",
    "unique_taxi_ids_df = pd.DataFrame({'Person ID': unique_taxi_ids})\n",
    "unique_taxi_ids_df = unique_taxi_ids_df.sort_values(by='Person ID')\n",
    "unique_taxi_ids_df = unique_taxi_ids_df.reset_index(drop=True)\n",
    "unique_taxi_ids_df.to_csv('data/tdrive_nodes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c87d1-6fc5-4beb-8e45-d06b5dd52a09",
   "metadata": {},
   "source": [
    "# 5. Add Geohash codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbd2347-4336-433a-8a57-f282be01ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_geohash(lat, lon):\n",
    "\treturn gh.encode(lat, lon,  precision=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57fb9f5-a963-493b-a946-1707587df1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13818537/13818537 [07:20<00:00, 31374.56it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "codes = []\n",
    "columns = gps_data.columns.to_list()\n",
    "lat = columns.index('Latitude')\n",
    "lon = columns.index('Longitude')\n",
    "for i in tqdm(range(len(gps_data))):\n",
    "    codes.append(create_geohash(gps_data.iat[i,lat], gps_data.iat[i,lon]))\n",
    "\n",
    "geohash_data = gps_data.copy(deep=True)\n",
    "geohash_data['Geohash'] = codes\n",
    "\n",
    "geohash_data.to_csv('data/tdrive_geohash_size_8.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd34284-322c-45ea-acbf-0e4df49a4417",
   "metadata": {},
   "source": [
    "# 6. Group users based on geohash codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4726c390-68ee-4c60-8dc3-35c790933760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pairs of meetings for two persons\n",
    "def createEdges(geohash_data):\n",
    "\n",
    "\tlocations_meets = []\n",
    "\tprint(\"loaded\")\n",
    "\tgeohash_count = len(geohash_data['Geohash'].unique())\n",
    "\tprint(geohash_count)\n",
    "\tprint(\"grouping...\")\n",
    "\tcodes = geohash_data.groupby('Geohash')\n",
    "\tprint(\"grouped\")\n",
    "\n",
    "\tt = 0\n",
    "\tk = 0\n",
    "\tfor code, group in codes:\n",
    "\t\tt += 1\n",
    "\t\tlat = group['Latitude'].mean()\n",
    "\t\tlon = group['Longitude'].mean()\n",
    "\t\tperson_ids = group['Person ID'].values.tolist()\n",
    "\t\ttimes = group['Timestamp'].values.tolist()\n",
    "\n",
    "\t\tlocations_meets.append({\n",
    "\t\t\t'Geohash': code,\n",
    "\t\t\t\"persons\": person_ids,\n",
    "\t\t\t\"times\": times,\n",
    "\t\t\t'Latitude': lat,\n",
    "\t\t\t'Longitude': lon\n",
    "\t\t})\n",
    "\t\tif len(locations_meets) > 1000:\n",
    "\t\t\tif not (os.path.isdir('data/tdrive_edges/')):\n",
    "\t\t\t\tos.makedirs('data/tdrive_edges/')\n",
    "\n",
    "\t\t\twith open('data/tdrive_edges/tdrive_meets_'+str(k)+'.json', 'w') as json_file:\n",
    "\t\t\t\tjson.dump(locations_meets, json_file, indent=4)\n",
    "\n",
    "\t\t\tk += 1\n",
    "\t\t\tlocations_meets = []\n",
    "\t\t\n",
    "\n",
    "\tprint(str(t / float(geohash_count)), t, '/', geohash_count)\n",
    "\n",
    "\tif len(locations_meets) > 0:\n",
    "\t\tif not (os.path.isdir('data/tdrive_edges/')):\n",
    "\t\t\tos.makedirs('data/tdrive_edges/')\n",
    "\n",
    "\t\twith open('data/tdrive_edges/tdrive_meets_' + str(k) + '.json', 'w') as json_file:\n",
    "\t\t\tjson.dump(locations_meets, json_file, indent=4)\n",
    "\n",
    "\treturn k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86eb8cf9-f65d-4064-8ed5-b77ba39f1a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "587021\n",
      "grouping...\n",
      "grouped\n",
      "1.0 587021 / 587021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 586/586 [00:12<00:00, 45.60it/s]\n"
     ]
    }
   ],
   "source": [
    "k = createEdges(geohash_data)\n",
    "\n",
    "edges = []\n",
    "for i in tqdm(range(k)):\n",
    "\td = pd.read_json('data/tdrive_edges/tdrive_meets_'+str(i)+'.json')\n",
    "\tedges.append(d.copy(deep=True))\n",
    "edges = pd.concat(edges)\n",
    "edges.to_csv('data/tdrive_edges_size_8.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f2e65-0620-4a25-a071-226b171c617b",
   "metadata": {},
   "source": [
    "# 7. Geohash meets without time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a971791-0e70-41e1-9cfc-9da9538b64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_meet_geohash():\n",
    "\tedges_all = pd.read_csv('data/tdrive_edges_size_8.csv')\n",
    "\tpersons = []\n",
    "\tp_times = []\n",
    "\tmax_t = []\n",
    "\tmin_t = []\n",
    "\tcount_p = []\n",
    "\tcount_t = []\n",
    "\tt_diff = []\n",
    "\tfor i in tqdm(range(len(edges_all))):\n",
    "\t\tx = json.loads(edges_all.iloc[i]['times'].replace(\"'\",\"\\\"\"))\n",
    "\t\tp = json.loads(edges_all.iloc[i]['persons'])\n",
    "\t\tassert len(x)==len(p)\n",
    "\t\tt = {}\n",
    "\t\tfor j in np.unique(p):\n",
    "\t\t\tt[str(j)]=[]\n",
    "\t\tfor j in range(len(x)):\n",
    "\t\t\tt[str(p[j])].append(x[j])\n",
    "\t\tpersons.append(json.dumps(np.unique(p).tolist()))\n",
    "\t\tp_times.append(json.dumps(t))\n",
    "\t\tcount_p.append(len(np.unique(p)))\n",
    "\t\tcount_t.append(len(x))\n",
    "\t\txt = np.array(x, dtype='datetime64[s]')\n",
    "\t\tt_diff.append(abs(np.timedelta64(xt.max() - xt.min(), 's').astype('int')))\n",
    "\n",
    "\tmeet_edges = edges_all.copy(deep=True)\n",
    "\tmeet_edges['persons']=persons\n",
    "\tmeet_edges['times']=p_times\n",
    "\tmeet_edges['count_p']=count_p\n",
    "\tmeet_edges['count_t']=count_t\n",
    "\tmeet_edges['diff_time'] = t_diff\n",
    "\n",
    "\tmeet_edges.to_csv(\"data/tdrive_groupby_geohash_size_8.csv\", index=False)\n",
    "\tmeet_edges[(meet_edges['diff_time'] >= 0) & (meet_edges['count_p'] > 1)].to_csv(\"data/tdrive_meet_geohash_size_8.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67fa9747-5d5e-4b97-b58b-c6c3f444c374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 586586/586586 [01:26<00:00, 6788.24it/s]\n"
     ]
    }
   ],
   "source": [
    "create_meet_geohash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0775b59-d573-4d3c-8fc4-60f99a38c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_meet_edges_without_time():\n",
    "\tprint('loading')\n",
    "\tmeet_geohash = pd.read_csv(\"data/tdrive_meet_geohash_size_8.csv\")\n",
    "\tmeets = {}\n",
    "\tprint('starting')\n",
    "\tfor i in tqdm(range(len(meet_geohash))):\n",
    "\t\tp = json.loads(meet_geohash.iloc[i]['persons'])\n",
    "\t\tfor a in range(len(p)):\n",
    "\t\t\ta_key = p[a]\n",
    "\t\t\tfor b in range(a+1,len(p)):\n",
    "\t\t\t\tb_key = p[b]\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\ta_in = a_key in meets.keys()\n",
    "\t\t\t\tb_in = b_key in meets.keys()\n",
    "\t\t\t\tif not a_in and not b_in:\n",
    "\t\t\t\t\tmeets[a_key]=set()\n",
    "\t\t\t\t\tmeets[a_key].add(b_key)\n",
    "\t\t\t\telif a_in:\n",
    "\t\t\t\t\tmeets[a_key].add(b_key)\n",
    "\t\t\t\telif b_in:\n",
    "\t\t\t\t\tmeets[b_key].add(a_key)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\traise Exception(\"\")\n",
    "\n",
    "\tedges = []\n",
    "\tfor a in meets.keys():\n",
    "\t\tfor b in meets[a]:\n",
    "\t\t\tedges.append([a,b])\n",
    "\tedges = pd.DataFrame(edges, columns=['A', 'B'])\n",
    "\tedges.to_csv('data/tdrive_meet_edges.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ef6d921-fd98-4282-b3ba-22daf12c9f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading\n",
      "starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 369651/369651 [02:20<00:00, 2623.15it/s] \n"
     ]
    }
   ],
   "source": [
    "create_meet_edges_without_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfe9c27-e496-4eb9-98a0-b48c36023066",
   "metadata": {},
   "source": [
    "# 8. Geohash meets with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "451c5ddb-d32b-4d40-81c2-6d85700824f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_meet_edges(min_seconds, max_seconds, min_times, max_times):\n",
    "\n",
    "\tprint('loading')\n",
    "\tmeet_geohash = pd.read_csv(\"data/tdrive_meet_geohash_size_8.csv\")\n",
    "\tmeet_geohash = meet_geohash[(meet_geohash['count_t'] <= max_times) & (meet_geohash['count_t'] >= min_times)].copy(deep=True)\n",
    "\tmeet_geohash.reset_index(drop=True, inplace=True)\n",
    "\tmeets = {}\n",
    "\tprint('starting')\n",
    "\tfor i in tqdm(range(len(meet_geohash))):\n",
    "\t\tusers = json.loads(meet_geohash.iloc[i]['times'])\n",
    "\t\tkeys = list(users.keys())\n",
    "\t\tfor a in range(len(keys)):\n",
    "\t\t\ta_key = keys[a]\n",
    "\t\t\ta_times = np.array(users[a_key], dtype='datetime64[s]')\n",
    "\t\t\tfor b in range(a+1,len(keys)):\n",
    "\t\t\t\tb_key = keys[b]\n",
    "\t\t\t\tb_times = np.array(users[b_key], dtype='datetime64[s]')\n",
    "\n",
    "\t\t\t\tfor a_time in a_times:\n",
    "\t\t\t\t\tfor b_time in b_times:\n",
    "\t\t\t\t\t\tdiff = abs(np.timedelta64(b_time - a_time, 's').astype('int'))\n",
    "\t\t\t\t\t\tif min_seconds <= diff <= max_seconds:\n",
    "\t\t\t\t\t\t\ta_in = a_key in meets.keys()\n",
    "\t\t\t\t\t\t\tb_in = b_key in meets.keys()\n",
    "\t\t\t\t\t\t\tif not a_in and not b_in:\n",
    "\t\t\t\t\t\t\t\tmeets[a_key]=set()\n",
    "\t\t\t\t\t\t\t\tmeets[a_key].add(b_key)\n",
    "\t\t\t\t\t\t\telif a_in:\n",
    "\t\t\t\t\t\t\t\tmeets[a_key].add(b_key)\n",
    "\t\t\t\t\t\t\telif b_in:\n",
    "\t\t\t\t\t\t\t\tmeets[b_key].add(a_key)\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\traise Exception(\"\")\n",
    "\n",
    "\tfor i in meets.keys():\n",
    "\t\tmeets[i]=list(meets[i])\n",
    "\t\t\n",
    "\tif not (os.path.isdir('data/meets/')):\n",
    "\t\t\tos.makedirs('data/meets/')\n",
    "\t\t\t\n",
    "\twith open('data/meets/meets_size_8_'+str(min_seconds)+'-'+str(max_seconds)+'s-'+str(min_times)+'-'+str(max_times)+'times.json', \"w\") as write_file:\n",
    "\t\tjson.dump(meets, write_file)\n",
    "\n",
    "\tedges = []\n",
    "\tfor a in meets.keys():\n",
    "\t\tfor b in meets[a]:\n",
    "\t\t\tedges.append([a,b])\n",
    "\tedges = pd.DataFrame(edges, columns=['A', 'B'])\n",
    "\tedges.to_csv('data/meets/tdrive_meet_edges_size_8_'+str(min_seconds)+'-'+str(max_seconds)+'s-'+str(min_times)+'-'+str(max_times)+'times.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "647833af-8b8e-4056-bc85-a952c0af2e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading\n",
      "starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338500/338500 [09:26<00:00, 597.70it/s] \n"
     ]
    }
   ],
   "source": [
    "# create_meet_edges(0, 120, 0, 10)\n",
    "create_meet_edges(0, 120, 0, 100)\n",
    "# create_meet_edges(0, 120, 100, 1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
